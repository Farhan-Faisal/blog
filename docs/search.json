[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Environments with Conda and Docker",
    "section": "",
    "text": "Introduction\nIn data science, we frequently rely on many packages. With Python, we commonly use libraries such as pandas, numpy, scikit-learn, and many others. However, these libraries are often compatible only with specific versions of each other. This is where Conda environments come into play.\n\n\nWhy Use Conda Environments?\nConda environments allow us to list all the necessary packages for a project, along with their specific versions, in a single file. This way, when someone else wants to use our project, they can simply install all the required packages from this list, ensuring compatibility.\nYou might wonder: why do we need environments in the first place? Why can’t we just install the packages directly?\nThe answer is simple: you may have multiple projects, each requiring a different set of packages. One project might need Python 3.11, while another requires Python 3.9. By using environments, you can maintain separate sets of installed packages and activate the appropriate set depending on the project you are working on.\nIn the next section, I will show you how to set up an environment file and install a conda environment from an environment file.\n\n\nSetting Up a Conda Environment\nStep 1: Installing Miniconda To get started, you need to install Miniconda, a lightweight version of Anaconda that provides just the essentials for managing Conda environments.\nFollow the detailed instructions provided here for installing Miniconda.\nFor a quick installation on macOS (ARM64), open your terminal and run the following commands:\nmkdir -p ~/miniconda3\ncurl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh -o ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm ~/miniconda3/miniconda.sh\nsource ~/miniconda3/bin/activate\nconda init --all\nStep 2: Creating the environment file\nIn your project folder, make the environment file named environment.yaml Open the file and paste the following:\nname: tutorial\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - numpy=1.26.0\n  - pandas=2.2.3\n  - pip=24.3.1\n  - python=3.11\n  - scikit-learn=1.5.2\n  - scipy=1.14.1\n  - quarto=1.5.57\nStep 3: Creating the environemnt from environment.yaml\nWhile in the directory where the environemnt.yaml is locatied, run:\nconda env create -f environment.yaml\nYou can then activate the conda environment using:\nconda activate tutorial\n\n\nGoing One Step Further: Using Conda Lock Files\nWhen you install an environment from an environment file, you might notice that additional packages, which were not explicitly listed, are also installed. For example, when we create the environment form our previous environment file, we see packages like xx installed:\n\n\n\nSubdependency Installation\n\n\nWhy does this happen? This occurs because in the environment file, we only specify high-level packages.\nBut when installing a Conda environment across different operating systems, Conda may install different versions of these low-level packages. Consequently, even though the high-level packages remain the same, the overall environment may differ across platforms. Additionally, since we haven’t specified exact versions for the low-level dependencies, installing the environment can take longer as Conda needs to resolve compatible versions on its own.\n\n\nThe Solution? Conda Lock Files\nConda lock files are platform-specific files that list the exact versions of all dependency packages, including low-level ones, for a given environment. By using these lock files, you can ensure that the environment is identical across different platforms.\nIn the next section, I will demonstrate how to generate and use Conda lock files to create consistent environments across various operating systems.\n\n\nGenerating and Using Conda Lock Files\nLet’s assume we are working with the following environment file (environment.yaml):\nname: tutorial\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - numpy=1.26.0\n  - pandas=2.2.3\n  - pip=24.3.1\n  - python=3.11\n  - scikit-learn=1.5.2\n  - scipy=1.14.1\n  - quarto=1.5.57\nTo generate a lock file for different platforms, run the appropriate command below:\nFor macOS (ARM-based, e.g., Apple Silicon):\nconda-lock -k explicit -p osx_arm64 -f environment.yaml\nFor macOS (intel):\nconda-lock -k explicit -p osx-64 -f environment.yaml\nFor Linux:\nconda-lock -k explicit -p linux-64 -f environment.yaml\nFor Windows:\nconda-lock -k explicit -p win-64 -f environment.yaml\nAssuming you are on macOS ARM, you can create an environment from the lock file by running:\nconda-lock install --name tutorial conda-osx-arm64.lock\nYou should generate all four conda lock files to ensure your collaborators have the necessary files for their respective platforms. Running the four commands will produce the following files:\n\n\n\nFour Lock Files\n\n\nNote:\n- The –name flag specifies the environment name (tutorial in this case). - The lock file ensures the exact versions of dependencies are installed, making the environment fully reproducible across different platforms.\n\n\nFor Real Pros- Going even further\nRemember when I mentioned that using conda-lock allows us to recreate exact environment copies, including exact versions for subdependencies? I wasn’t entirely correct.\nWhile conda-lock does pin exact versions of subdependencies, there are certain system or OS-level dependencies that it doesn’t account for. These dependencies can vary depending on the operating system where the environment is created— whether it’s Linux, Windows, or macOS.\nThis is where Docker comes in. Docker allows us to package an environment along with the OS kernel, such as Linux. Whenever someone runs our Docker container, they’ll be running the project in a Linux environment with the exact same dependencies. By using Docker, we ensure that the project environment is exactly the same for all collaborators, including system-level dependencies.\nIn the next stage, I’ll guide you through the steps of setting up a Docker container with a copy of your environment from a Linux perspective.\n\n\nDocker Steps\nStep 1: Create an account on DockerHub\nYou need a DockerHub account to manage and store your Docker images. Sign up if you don’t already have an account.\nStep 2: Download and Install Docker\nStep 3: Make the docker file\nAssuming you have the conda-lock file in your working project directory, create a file called Dockerfile in your project directory.\nFROM quay.io/jupyter/minimal-notebook:afe30f0c9ad8\nCOPY conda-linux-64.lock /tmp/conda-linux-64.lock\n\nUSER root\n\n# install lmodern for Quarto PDF rendering\nRUN sudo apt update \\\n    && sudo apt install -y lmodern\n\nUSER $NB_UID\n\nRUN mamba update --quiet --file /tmp/conda-linux-64.lock \\\n    && mamba clean --all -y -f \\\n    && fix-permissions \"${CONDA_DIR}\"  \\\n    && fix-permissions \"/home/${NB_USER}\"\nRUN pip install -r /tmp/requirements.txt\nBriefly, - FROM command tells us we are buiding off an existing environment (linux in this case) - COPY command is used to transfer your conda lock file into the docker container - RUN commans installs all the dependencies in teh docker container\nStep 4: Build the Docker Image\ndocker build -t username/imagename:tag .\n\nThe username should be your dockerhub user name.\nThe image name is your choice.\nThe tag is your choice.\n\nStep 5: Puch image to Docker Hub\ndocker push username/imagename:tag\n\n\nUsing the Docker Image\nStep 1: Make the Docker Compose File in your project directory and name it docker-compose.yaml\nservices:\n  pull-image:\n    image: username/imagename:tag\n    ports:\n      - \"8888:8888\" \n    volumes:\n      - \"${PWD}:/app/data\" \n    working_dir: /app/data\n    deploy:\n      resources:\n        limits:\n          memory: 10G\n    platform: linux/amd64\nStep 2: Install docker-compose\nsudo curl -L \"https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nVerify installation using:\ndocker-compose --version\nStep 3: Pull and Run the Docker Image\nIn your project directory, run:\ndocker-compose up\nFollow the instructions on your terminal. That should lead you to a jupyter notebook where you can work on this project inside the docker container.\nStep 4: Cleanup After finishing your work, close the Docker container:\ndocker-compose down\n\n\nConclusion\nWith this knowledge, you are now ready to collaborate effortlessly with others and ensure that your projects run smoothly on any system. Happy coding!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 14, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 11, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]